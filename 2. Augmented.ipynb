{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Mengecek gambar rusak...\n",
      "âœ… Pengecekan selesai!\n",
      "ğŸ”„ Augmenting class Acute & Chronic Rhinitis from 16 to 300\n",
      "ğŸ“‰ Reducing class Acute & Chronic Rhinitis from 307 to 300\n",
      "ğŸ”„ Augmenting class Acute & Chronic Sinusitis from 12 to 300\n",
      "ğŸ“‰ Reducing class Acute & Chronic Sinusitis from 305 to 300\n",
      "ğŸ”„ Augmenting class Adenoid Hypertrophy from 9 to 300\n",
      "ğŸ“‰ Reducing class Adenoid Hypertrophy from 305 to 300\n",
      "ğŸ”„ Augmenting class Allergic Rhinitis from 11 to 300\n",
      "ğŸ“‰ Reducing class Allergic Rhinitis from 307 to 300\n",
      "ğŸ”„ Augmenting class Cavum Nasi Tumor from 11 to 300\n",
      "âš ï¸  Gagal membaca: C:\\Users\\asusm\\Dropbox\\PC\\Downloads\\TA\\dataset\\Cavum Nasi Tumor\\230712_125502_QQ.jpg (Gambar mungkin rusak)\n",
      "ğŸ“‰ Reducing class Cavum Nasi Tumor from 304 to 300\n",
      "ğŸ”„ Augmenting class Concha from 7 to 300\n",
      "ğŸ“‰ Reducing class Concha from 302 to 300\n",
      "ğŸ”„ Augmenting class Fallopian Tubes from 17 to 300\n",
      "ğŸ“‰ Reducing class Fallopian Tubes from 314 to 300\n",
      "ğŸ”„ Augmenting class Normal from 34 to 300\n",
      "ğŸ“‰ Reducing class Normal from 328 to 300\n",
      "ğŸ”„ Augmenting class Normal Nasofarings from 7 to 300\n",
      "ğŸ“‰ Reducing class Normal Nasofarings from 301 to 300\n",
      "ğŸ”„ Augmenting class Polyps from 25 to 300\n",
      "ğŸ“‰ Reducing class Polyps from 319 to 300\n",
      "ğŸ”„ Augmenting class Septum Deviation from 5 to 300\n",
      "ğŸ”„ Augmenting class Snot from 9 to 300\n",
      "ğŸ“‰ Reducing class Snot from 304 to 300\n",
      "ğŸ‰ Proses selesai! Semua kelas memiliki tepat 300 gambar.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "import random\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import shutil\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "\n",
    "# Direktori dataset\n",
    "base_dir = \"C:\\\\Users\\\\asusm\\\\Dropbox\\\\PC\\\\Downloads\\\\TA\\\\dataset\"\n",
    "output_dir = \"C:\\\\Users\\\\asusm\\\\Dropbox\\\\PC\\\\Downloads\\\\TA\\\\Split\\\\Augmented\"\n",
    "\n",
    "# Cek dan hapus gambar rusak sebelum augmentasi\n",
    "print(\"ğŸ” Mengecek gambar rusak...\")\n",
    "for class_dir in os.listdir(base_dir):\n",
    "    class_path = os.path.join(base_dir, class_dir)\n",
    "    image_paths = glob(os.path.join(class_path, \"*.jpg\"))\n",
    "\n",
    "    for img_path in image_paths:\n",
    "        try:\n",
    "            img = Image.open(img_path)\n",
    "            img.verify()  # Cek apakah gambar valid\n",
    "        except (OSError, IOError):\n",
    "            print(f\"ğŸš¨ Menghapus gambar rusak: {img_path}\")\n",
    "            os.remove(img_path)  # Hapus gambar yang korup\n",
    "\n",
    "print(\"âœ… Pengecekan selesai!\")\n",
    "\n",
    "# Augmentasi khusus untuk oversampling\n",
    "oversample_datagen = ImageDataGenerator(\n",
    "    rotation_range=30, \n",
    "    width_shift_range=0.2, \n",
    "    height_shift_range=0.2, \n",
    "    shear_range=0.2, \n",
    "    zoom_range=0.2, \n",
    "    horizontal_flip=True, \n",
    "    fill_mode=\"nearest\",\n",
    "    preprocessing_function=preprocess_input  # Preprocessing untuk ResNet50\n",
    ")\n",
    "\n",
    "# Membuat direktori untuk menyimpan dataset dengan jumlah terbatas\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Target jumlah gambar per kelas\n",
    "target_num = 300\n",
    "\n",
    "# Periksa setiap kelas di direktori pelatihan\n",
    "for class_dir in os.listdir(base_dir):\n",
    "    class_path = os.path.join(base_dir, class_dir)\n",
    "    output_class_path = os.path.join(output_dir, class_dir)\n",
    "\n",
    "    # Membuat direktori untuk kelas jika belum ada\n",
    "    if not os.path.exists(output_class_path):\n",
    "        os.makedirs(output_class_path)\n",
    "\n",
    "    # Daftar gambar dalam kelas\n",
    "    image_paths = glob(os.path.join(class_path, \"*.jpg\"))\n",
    "    num_images = len(image_paths)\n",
    "\n",
    "    # Jika gambar kurang dari target, tambahkan melalui augmentasi\n",
    "    if num_images < target_num:\n",
    "        print(f\"ğŸ”„ Augmenting class {class_dir} from {num_images} to {target_num}\")\n",
    "        save_count = 0\n",
    "\n",
    "        # Augmentasi hingga mencapai jumlah target\n",
    "        while num_images + save_count < target_num:\n",
    "            for img_path in image_paths:\n",
    "                try:\n",
    "                    img = Image.open(img_path)\n",
    "                    img = img.resize((180, 180))  # Resize agar seragam\n",
    "                    img = np.array(img)  # Konversi ke array numpy\n",
    "                    img = np.expand_dims(img, axis=0)  # Tambahkan dimensi batch\n",
    "\n",
    "                    # Generate batch augmentasi dengan batch size 64\n",
    "                    for batch in oversample_datagen.flow(img, batch_size=64, save_to_dir=output_class_path, save_prefix=class_dir, save_format='jpg'):\n",
    "                        save_count += batch.shape[0]  # Menghitung jumlah gambar yang disimpan\n",
    "                        if num_images + save_count >= target_num:\n",
    "                            break\n",
    "                except (OSError, IOError):\n",
    "                    print(f\"âš ï¸  Gagal membaca: {img_path} (Gambar mungkin rusak)\")\n",
    "\n",
    "            if num_images + save_count >= target_num:\n",
    "                break\n",
    "\n",
    "    # Salin semua gambar asli dan hasil augmentasi ke direktori output\n",
    "    current_images = glob(os.path.join(class_path, \"*.jpg\"))\n",
    "    for img_path in current_images:\n",
    "        shutil.copy(img_path, output_class_path)\n",
    "\n",
    "    # Setelah augmentasi, hitung jumlah gambar\n",
    "    final_image_paths = glob(os.path.join(output_class_path, \"*.jpg\"))\n",
    "    final_num_images = len(final_image_paths)\n",
    "\n",
    "    # Jika gambar lebih dari target, hapus secara acak\n",
    "    if final_num_images > target_num:\n",
    "        print(f\"ğŸ“‰ Reducing class {class_dir} from {final_num_images} to {target_num}\")\n",
    "        excess_images = random.sample(final_image_paths, final_num_images - target_num)\n",
    "        for img_path in excess_images:\n",
    "            os.remove(img_path)\n",
    "\n",
    "    # Jika masih kurang, augmentasi tambahan hingga tepat 150\n",
    "    elif final_num_images < target_num:\n",
    "        print(f\"ğŸ”„ Completing class {class_dir} to {target_num}\")\n",
    "        missing = target_num - final_num_images\n",
    "        while missing > 0:\n",
    "            for img_path in image_paths:\n",
    "                try:\n",
    "                    img = Image.open(img_path)\n",
    "                    img = img.resize((180, 180))  # Resize agar seragam\n",
    "                    img = np.array(img)  # Konversi ke array numpy\n",
    "                    img = np.expand_dims(img, axis=0)  # Tambahkan dimensi batch\n",
    "\n",
    "                    for batch in oversample_datagen.flow(img, batch_size=64, save_to_dir=output_class_path, save_prefix=class_dir, save_format='jpg'):\n",
    "                        missing -= batch.shape[0]  # Menghitung jumlah gambar yang disimpan\n",
    "                        if missing <= 0:\n",
    "                            break\n",
    "                except (OSError, IOError):\n",
    "                    print(f\"âš ï¸  Gagal membaca: {img_path} (Gambar mungkin rusak)\")\n",
    "\n",
    "            if missing <= 0:\n",
    "                break\n",
    "\n",
    "print(\"ğŸ‰ Proses selesai! Semua kelas memiliki tepat 300 gambar.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
